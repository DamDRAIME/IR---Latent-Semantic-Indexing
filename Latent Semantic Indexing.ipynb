{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval\n",
    "***\n",
    "## | Latent Semantic Indexing |\n",
    "\n",
    "Damien Draime - Apr 19\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Typically, information is retrieved by literally matching terms in documents with those of a query. However, **lexical matching methods** can be inaccurate when they are used to match a user’s query. Since there are usually many ways to express a given concept (synonymy), the literal terms in a user’s query may not match those of a relevant document. In addition, most words have multiple meanings (polysemy), so terms in a user’s query will literally match terms in irrelevant documents. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document.<br>\n",
    "**Latent Semantic Indexing** (**LSI**) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A truncated singular value decomposition (SVD) is used to estimate the structure in word usage across documents. Retrieval is performed using the database of singular values and vectors obtained from the truncated SVD.<br><br>\n",
    " - [Motivation](#Motivation)\n",
    " - [LSI and Linear Algebra](#LSI-and-Linear-Algebra)\n",
    " - [LSI for retrieval](#LSI-for-retrieval)\n",
    "     - [Variant 01 - Ak](#Variant-01---Ak)\n",
    "     - [Variant 02 - Vk](#Variant-02---Vk)\n",
    "     - [Variant 03 - Expand](#Variant-03---Expand)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "*Based on __[Deerwester et al. - Indexing by Latent Semantic Analysis](http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf)__, __[Uni-Freiburg's Information Retrieval - Lecture 10](https://daphne.informatik.uni-freiburg.de/ws1617/InformationRetrieval/svn-public/public/slides/lecture-10.pdf)__, and __[KU Leuven's Text-Based Information Retrieval - Lecture 04](https://p.cygnus.cc.kuleuven.be/bbcswebdav/pid-22306777-dt-content-rid-175870631_2/courses/B-KUL-H02C8a-1819/Chapter3-AdvancedRepresentations-Part1.pdf)__.*<br>\n",
    "*Other sources: __[Stanford's NLP website](https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html)__.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "Let's look at a toy example made of a collection of D documents and a vocabulary of W terms. For this example, D=6, and W=4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document 1</th>\n",
       "      <th>document 2</th>\n",
       "      <th>document 3</th>\n",
       "      <th>document 4</th>\n",
       "      <th>document 5</th>\n",
       "      <th>document 6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surfing</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          document 1  document 2  document 3  document 4  document 5  \\\n",
       "index                                                                  \n",
       "internet           1           1           0           1           0   \n",
       "web                1           0           1           1           0   \n",
       "surfing            1           1           1           2           1   \n",
       "beach              0           0           0           1           1   \n",
       "\n",
       "          document 6  \n",
       "index                 \n",
       "internet           0  \n",
       "web                0  \n",
       "surfing            1  \n",
       "beach              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "A = pd.read_csv('dataset/toy_example.csv',index_col=0)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is thus a matrix representation of the documents and the terms that compose each of them. We will refer to this matrix as __A__<sub>m x n</sub>. Each column refers to a specific document, each row to a term. A<sub>ij</sub> indicates the frequency of the term i in the document j (*tf<sub>ij</sub>*).<br>\n",
    "*E.g.: the term `surfing` appears in all documents once, except for `document 4` where it appears twice.*<br><br>\n",
    "Intuitively, we notice that the first 3 documents are related to \"surfing the web\", while the last 2 are about \"beach/surfing waves\". Hence we can identify that there are two concepts. *`document 4` is a mix of the two concepts.*<br><br>\n",
    "Let's assume that we have a query: \"web surfing\", represented as a vector **_q_**: $[0 1 1 0]$. In order to retrieve the relevant documents for this query, we use a **lexical matching method** by doing a dot product A<sub>j</sub> q. This gives us a similarity score between the query and the document j. <br>(*Note that this similarity score is based on term frequencies and thus has a bias towards long documents. This will be ignored here but one might want to first normalize the tf<sub>ij</sub>.*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 1 has a relevance score of 2\n",
      "document 2 has a relevance score of 1\n",
      "document 3 has a relevance score of 2\n",
      "document 4 has a relevance score of 3\n",
      "document 5 has a relevance score of 1\n",
      "document 6 has a relevance score of 1\n"
     ]
    }
   ],
   "source": [
    "q = np.array([0, 1, 1, 0])\n",
    "for document in A:\n",
    "    print (document, 'has a relevance score of', A[document].dot(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then use this relevance scores to rank the documents and thus display to the user only the n<sup>th</sup> first documents that we consider relevant for his/her query. However, you will quickly notice a problem with this approach. `document 2` should be considered as relevant since it is also related to \"surfing the web\". But since the term `web` from the query does not match the term `internet` from the document, the relevance score dropped. Thus, althought `document 2` and `document 3` should intuitively have the same relevance, `document 2` has a lower similarity score because our approach only consider exact match.<br>\n",
    "Actually, `internet` and `web` are *synonyms* but this notion is not integrated in the lexical matching approach. Another problem can arise with *polysems* such as `surfing`: its meaning depends on the context.<br><br>Those are not benign problems and occur more frequently than we think. Consider the following set of terms: *bank, finance, river, stream, money.*<br><br>\n",
    "What if we adjusted A so that we take into account the synonyms ? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document 1</th>\n",
       "      <th>document 2</th>\n",
       "      <th>document 3</th>\n",
       "      <th>document 4</th>\n",
       "      <th>document 5</th>\n",
       "      <th>document 6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surfing</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          document 1  document 2  document 3  document 4  document 5  \\\n",
       "index                                                                  \n",
       "internet           1           1           1           1           0   \n",
       "web                1           1           1           1           0   \n",
       "surfing            1           1           1           2           1   \n",
       "beach              0           0           0           1           1   \n",
       "\n",
       "          document 6  \n",
       "index                 \n",
       "internet           0  \n",
       "web                0  \n",
       "surfing            1  \n",
       "beach              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_adjusted = A.copy()\n",
    "for document in A_adjusted:\n",
    "    if A_adjusted[document]['internet'] == 1 or A_adjusted[document]['web'] == 1:\n",
    "        A_adjusted[document]['internet'] = 1\n",
    "        A_adjusted[document]['web'] = 1\n",
    "A_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 1 has a relevance score of 2\n",
      "document 2 has a relevance score of 2\n",
      "document 3 has a relevance score of 2\n",
      "document 4 has a relevance score of 3\n",
      "document 5 has a relevance score of 1\n",
      "document 6 has a relevance score of 1\n"
     ]
    }
   ],
   "source": [
    "for document in A_adjusted:\n",
    "    print (document, 'has a relevance score of', A_adjusted[document].dot(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the similarity score for `document 2` and `document 3` are the same. This seems better, right ? Well, this is the idea behind **Latent Semantic Indexing**.<br>\n",
    "Latent Semantic Indexing represents queries and document with vectors by mapping the term vectors of documents and query into a *low dimensionsal space* which is associated with statistical **concepts**. This would allow the retrieval of documents even when they are not indexed by the query index terms. The method used to reduce the dimensionality is the **Singular Value Decomposition**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI and Linear Algebra\n",
    "\n",
    "First, it is interesting to note that the new matrix `A_adjusted` has become a matrix of **rank** 2. (The original matrix A had a rank 4). this means that we can write each column/row as a linear combination of the same two base columns/rows. In our case the 2 base columns are `document 1`, and `document 5`. Respectively, the 2 base rows are `internet`, and `beach`.<br><br>\n",
    "*The rank of a matrix A corresponds to the maximal number of linearly independent columns of A. colomn rank = row rank. The rank of an m x n matrix is nonnegative integer and cannot be greater than either m or n:* $rank(A_{m x n}) \\leq min(m,n)$<br><br>\n",
    "It is important to notice that we can thus derive A_adjusted from those base columns and rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0]\n",
      " [1 1 1 1 0 0]\n",
      " [1 1 1 2 1 1]\n",
      " [0 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "B = A_adjusted[['document 1','document 5']]\n",
    "V = A_adjusted.loc[['internet','beach']]\n",
    "print(np.dot(B,V)) # returns again the original matrix A_adjsuted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns from the matrix B represent **underlying concepts** present in the collection of documents. And the columns in the matrix V are the representation of documents in the **concept/latent space**. It is crucial to note that this concept space is of a lower dimension (here 2) than original matrix A's dimension.<br>\n",
    "Note also that a column vector j from matrix V represents the linear combination for the two concepts (from B) for the document j. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the goal of LSI is to find a matrix __A<sub>k</sub>__ of lower rank than the original matrix __A__. Formally, given an m x n term-document matrix A, find a matrix A<sub>k</sub> of rank **k** such that k < rank(A) and the difference between A and A<sub>k</sub> is as small as possible.<br>\n",
    "$A_{k} = argmin_{A_{k} m x n\\;with\\;rank\\;k} ||A - A_{k}||$<br><br>\n",
    "This *difference* between the two matrices can be computed with the Frobenius-norm:<br>\n",
    "$||A - A_{k}|| = \\sqrt{\\sum_{ij} (A_{ij} - A_{k ij})^{2}}$\n",
    "<br><br>\n",
    "*Note that A<sub>k</sub> will still have the same dimension than A*.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question thus becomes: how do we find this A<sub>k</sub> ?<br>\n",
    "For this we can use the so-called **Singular Value Decomposition** (**SVD**) of the matrix A. SVD is based on the theorem that for any m x n matrix A of rank r, there exist matrices **U, D, and V**, such that\n",
    "$A = U . D . V$<br>\n",
    "_where<br>\n",
    " -U is an m x r matrix with pairwise orthogonal columns,<br>\n",
    " -D is an r x r matrix with non-zero entries only on its diagonal,<br>\n",
    " -V is an r x n matrix with pairwise orthogonal rows._\n",
    "<br><br>\n",
    "In numpy, it is very easy to find such decomposition for a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U is a (4, 4) matrix:\n",
      " [[-0.37 -0.47  0.71 -0.38]\n",
      " [-0.37 -0.47 -0.71 -0.38]\n",
      " [-0.78  0.12  0.00  0.61]\n",
      " [-0.34  0.74  0.00 -0.58]] \n",
      "\n",
      "D is a (4, 4) diagonal matrix:\n",
      " [[ 3.80  0.00  0.00  0.00]\n",
      " [ 0.00  1.55  0.00  0.00]\n",
      " [ 0.00  0.00  1.00  0.00]\n",
      " [ 0.00  0.00  0.00  0.38]] \n",
      "\n",
      "V is a (4, 6) matrix:\n",
      " [[-0.40 -0.30 -0.30 -0.69 -0.30 -0.30]\n",
      " [-0.53 -0.22 -0.22  0.03  0.56  0.56]\n",
      " [ 0.00  0.71 -0.71 -0.00  0.00  0.00]\n",
      " [-0.40  0.60  0.60 -0.34  0.06  0.06]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter = {\"float\": lambda x: (\"%5.2f\" % x)})\n",
    "U, D, V = np.linalg.svd(A)\n",
    "D = np.diag(D)\n",
    "V = V[:4,:]\n",
    "print ('U is a', U.shape, 'matrix:\\n', U, '\\n')\n",
    "print ('D is a', D.shape, 'diagonal matrix:\\n', D, '\\n')\n",
    "print ('V is a', V.shape, 'matrix:\\n', V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now verify the theorem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 0]\n",
      " [1 0 1 1 0 0]\n",
      " [1 1 1 2 1 1]\n",
      " [0 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(U.dot(D).dot(V).astype(int)) #returns the original matrix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A<sub>k</sub> can now be easily computed thanks to this SVD because, given a k, we have:<br>\n",
    "$A_k = U_k . D_k . V_k$<br>\n",
    "_where<br>\n",
    " -U<sub>k</sub> is an m x k matrix consiting of the first k columns of U,<br>\n",
    " -D<sub>k</sub> is an k x k matrix consisting of the upper k x k part of D,<br>\n",
    " -V<sub>k</sub> is an k x n matrix consisting of the first k rows of V._\n",
    " <br>![figure 01 - Ak](img/UDV.PNG)<br>\n",
    " *k* is a parameter _provided by the user_. It is related to the number of concepts that are present in the collection of documents. In our example, we can set it to 2 because we intuitively see that there are two main concepts. It is with this value that we will reduce the vector space. As such, k < W and k < D. In reality it is not always simple to determine the right value for k. <br>\n",
    " Let's now find this m x n matrix A<sub>k</sub> of rank k that minimizes $||A - A_{k}||$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document 1</th>\n",
       "      <th>document 2</th>\n",
       "      <th>document 3</th>\n",
       "      <th>document 4</th>\n",
       "      <th>document 5</th>\n",
       "      <th>document 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>0.942024</td>\n",
       "      <td>0.586451</td>\n",
       "      <td>0.586451</td>\n",
       "      <td>0.950631</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.008607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>0.942024</td>\n",
       "      <td>0.586451</td>\n",
       "      <td>0.586451</td>\n",
       "      <td>0.950631</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.008607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surfing</th>\n",
       "      <td>1.092679</td>\n",
       "      <td>0.861802</td>\n",
       "      <td>0.861802</td>\n",
       "      <td>2.078920</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.986242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beach</th>\n",
       "      <td>-0.089224</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.924022</td>\n",
       "      <td>1.013246</td>\n",
       "      <td>1.013246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          document 1  document 2  document 3  document 4  document 5  \\\n",
       "internet    0.942024    0.586451    0.586451    0.950631    0.008607   \n",
       "web         0.942024    0.586451    0.586451    0.950631    0.008607   \n",
       "surfing     1.092679    0.861802    0.861802    2.078920    0.986242   \n",
       "beach      -0.089224    0.133047    0.133047    0.924022    1.013246   \n",
       "\n",
       "          document 6  \n",
       "internet    0.008607  \n",
       "web         0.008607  \n",
       "surfing     0.986242  \n",
       "beach       1.013246  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 2\n",
    "Uk = U[:,:k]\n",
    "Dk = D[:k,:k]\n",
    "Vk = V[:k,:]\n",
    "Ak = Uk.dot(Dk).dot(Vk)\n",
    "Ak = pd.DataFrame(\n",
    "    data = Ak, \n",
    "    index = ['internet','web','surfing','beach'], \n",
    "    columns = ['document 1','document 2','document 3','document 4','document 5','document 6']\n",
    ")\n",
    "Ak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't it look to what the A_adjusted matrix we manually built in the section above ? A_k represents A as in a lower k dimensional space (rank k) in such a way that the representations in the original space are changed as little as possible when measured by the Frobenius-norm. <br>\n",
    "Let's now recompute the similarity score between the query **q** and __A<sub>k</sub>__ to see how performs LSI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 1 has a relevance score of 2.03\n",
      "document 2 has a relevance score of 1.45\n",
      "document 3 has a relevance score of 1.45\n",
      "document 4 has a relevance score of 3.03\n",
      "document 5 has a relevance score of 0.99\n",
      "document 6 has a relevance score of 0.99\n"
     ]
    }
   ],
   "source": [
    "for document in Ak:\n",
    "    print (document, 'has a relevance score of', round(Ak[document].dot(q),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, instead of the **Inner product similarity** we have used so far, we could also have decided to use the **Cosine similarity**. This defines the similarity as the cosine of the angle between query and document vectors:\n",
    "$sim(d_j,q) = \\frac{d_j^t . q}{||d_j|| ||q||}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 1 has a relevance score of 0.83\n",
      "document 2 has a relevance score of 0.85\n",
      "document 3 has a relevance score of 0.85\n",
      "document 4 has a relevance score of 0.81\n",
      "document 5 has a relevance score of 0.5\n",
      "document 6 has a relevance score of 0.5\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "for document in Ak:\n",
    "    print (document, 'has a relevance score of', 1 - round(spatial.distance.cosine(Ak[document],q),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI for retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant 01 - Ak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this variant, we use the matrix of lower rank that we defined earlier: **A<sub>k</sub>**. Recall that this matrix is also the matrix of rank k that is the closest to A. <br>\n",
    "However, this matrix A<sub>k</sub> is a dense matrix (i.e.: most of the entries are non-zero). This poses problem when it comes to store it and compute similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document 1</th>\n",
       "      <th>document 2</th>\n",
       "      <th>document 3</th>\n",
       "      <th>document 4</th>\n",
       "      <th>document 5</th>\n",
       "      <th>document 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>0.942024</td>\n",
       "      <td>0.586451</td>\n",
       "      <td>0.586451</td>\n",
       "      <td>0.950631</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.008607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>0.942024</td>\n",
       "      <td>0.586451</td>\n",
       "      <td>0.586451</td>\n",
       "      <td>0.950631</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.008607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surfing</th>\n",
       "      <td>1.092679</td>\n",
       "      <td>0.861802</td>\n",
       "      <td>0.861802</td>\n",
       "      <td>2.078920</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.986242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beach</th>\n",
       "      <td>-0.089224</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.924022</td>\n",
       "      <td>1.013246</td>\n",
       "      <td>1.013246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          document 1  document 2  document 3  document 4  document 5  \\\n",
       "internet    0.942024    0.586451    0.586451    0.950631    0.008607   \n",
       "web         0.942024    0.586451    0.586451    0.950631    0.008607   \n",
       "surfing     1.092679    0.861802    0.861802    2.078920    0.986242   \n",
       "beach      -0.089224    0.133047    0.133047    0.924022    1.013246   \n",
       "\n",
       "          document 6  \n",
       "internet    0.008607  \n",
       "web         0.008607  \n",
       "surfing     0.986242  \n",
       "beach       1.013246  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant 02 - Vk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we rather use the **V<sub>k</sub>** matrix which gives a representation of the documents in the k-dimensional concept space. This matrix will thus have as many rows as the concepts k defined by the user.<br>\n",
    "This variant has the advantage that it will be easier to query and store since the dimention will be k x D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document 1</th>\n",
       "      <th>document 2</th>\n",
       "      <th>document 3</th>\n",
       "      <th>document 4</th>\n",
       "      <th>document 5</th>\n",
       "      <th>document 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>concept 1</th>\n",
       "      <td>-0.399508</td>\n",
       "      <td>-0.302930</td>\n",
       "      <td>-0.302930</td>\n",
       "      <td>-0.694691</td>\n",
       "      <td>-0.295182</td>\n",
       "      <td>-0.295182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concept 2</th>\n",
       "      <td>-0.528702</td>\n",
       "      <td>-0.224807</td>\n",
       "      <td>-0.224807</td>\n",
       "      <td>0.027466</td>\n",
       "      <td>0.556167</td>\n",
       "      <td>0.556167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           document 1  document 2  document 3  document 4  document 5  \\\n",
       "concept 1   -0.399508   -0.302930   -0.302930   -0.694691   -0.295182   \n",
       "concept 2   -0.528702   -0.224807   -0.224807    0.027466    0.556167   \n",
       "\n",
       "           document 6  \n",
       "concept 1   -0.295182  \n",
       "concept 2    0.556167  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vk = pd.DataFrame(\n",
    "    data = Vk, \n",
    "    index = ['concept 1','concept 2'], \n",
    "    columns = ['document 1','document 2','document 3','document 4','document 5','document 6']\n",
    ")\n",
    "Vk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drawback is that one has to convert the query __q__ to this **concept space** though.<br>\n",
    "We know that:\n",
    "$$V_k^t = A_k^t . U_k . D_k^{-1}$$<br>\n",
    "Thus if we want to map a query q to this new space, we have to apply:\n",
    "$$q_k^t = q^t . U_k . D_k^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30, -0.22])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk = q.transpose().dot(Uk).dot(np.linalg.inv(Dk))\n",
    "qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 1 has a relevance score of 0.83\n",
      "document 2 has a relevance score of 0.85\n",
      "document 3 has a relevance score of 0.85\n",
      "document 4 has a relevance score of 0.81\n",
      "document 5 has a relevance score of 0.5\n",
      "document 6 has a relevance score of 0.5\n"
     ]
    }
   ],
   "source": [
    "for document in Vk:\n",
    "    print (document, 'has a relevance score of', 1 - round(spatial.distance.cosine(Ak[document],q),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to map also a new document into this concept space, we would have to apply the same transformation. Imagine that the new document `document 7` is $[2 1 3 0]$. Once mapped in the concept space it will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.91, -0.67])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_7 = np.array([2,1,3,0])\n",
    "document_7k = document_7.transpose().dot(Uk).dot(np.linalg.inv(Dk))\n",
    "document_7k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique of adding a new document to the new representation is called **folding in**. With this technique we can add new documents to the collection and map them to the concept space, as they come. However, since the LSI is not recomputed with those new documents, slowly the quality of the current representation will be degraded. At some point, it will be necessary to perform again a LSI to capture the concepts and information from the new documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant 03 - Expand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember what we did in the first section ? We manually adjusted the matrix A bused on our gut feelings about the underlying concepts present in the collection of documents. This allowed us to have a sparse matrix **A_adjusted**. <br>\n",
    "We can define a matrix **T<sub>k</sub>** that allows us to do this conversion for each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internet</th>\n",
       "      <th>web</th>\n",
       "      <th>surfing</th>\n",
       "      <th>beach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surfing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          internet  web  surfing  beach\n",
       "internet         1    1        0      0\n",
       "web              1    1        0      0\n",
       "surfing          0    0        1      0\n",
       "beach            0    0        0      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tk = pd.DataFrame(\n",
    "    data = [[1,1,0,0],[1,1,0,0],[0,0,1,0],[0,0,0,1]], \n",
    "    index = ['internet','web','surfing','beach'], \n",
    "    columns = ['internet','web','surfing','beach']\n",
    ")\n",
    "Tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix T is then used to expand the documents. If a document has `internet` then we expand it with `web`. If a document has `web`, we expand it with `internet`. <br>\n",
    "Here is an example with `document 2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "internet    1\n",
       "web         1\n",
       "surfing     1\n",
       "beach       0\n",
       "Name: document 2, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A['document 2'].dot(Tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trick is useful because we can now get a sparse matrix again. However, the question is \"How to get the matrix T in the first place?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the Latent Semantic Indexing claims that:\n",
    "- semantic information can be derived from a word-document co-occurrence matrix\n",
    "- dimensionality reduction is an essential part of this derivation\n",
    "- words and documents can be represented as points in the Euclidean space.\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
